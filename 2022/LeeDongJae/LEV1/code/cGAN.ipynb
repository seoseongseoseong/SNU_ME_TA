{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyPftEsFyLvXSD/gLkU4avM1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["cGAN Code from https://github.com/asiltureli/gan-in-colab"],"metadata":{"id":"yQughIFUkSKy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"XpfjaXJfjd3U"},"outputs":[],"source":["!pip install array2gif"]},{"cell_type":"code","source":["LATENT_SIZE = 100\n","EPOCH_SIZE  = 200\n","ROW_NUM     = 10\n","NUM_CLASSES = 10"],"metadata":{"id":"JSANVC4cjfr1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","\n","\n","def plot_epoch(images, n=100):\n","    '''  \n","    Visualize a single epoch of images\n","    Parameters\n","    ----------\n","    images : images of shape (b, c, x, y)\n","    n      : int, default: 100\n","             number of images to display. Must be a square number\n","    ''' \n","    \n","    if not isinstance(images, np.ndarray):\n","        images = images.detach().numpy()\n","\n","    rowcols = np.sqrt(n) \n","    plt.figure(figsize=(rowcols, rowcols))\n","    for index in range(n):\n","        plt.subplot(rowcols, rowcols, index + 1)\n","        plt.imshow(images[index, 0, :, :], cmap=\"binary\")\n","        plt.axis(\"off\")\n","    plt.show()"],"metadata":{"id":"8oKJmdFRjheU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class Generator(nn.Module):\n","  def __init__(self, latent_size = 100, n_class = NUM_CLASSES):\n","    super(Generator, self).__init__()\n","    self.label = nn.Embedding(n_class,10)\n","    self.layers = nn.Sequential(nn.Linear(latent_size + 10, 512),\n","                                nn.Dropout(),\n","                                nn.BatchNorm1d(512, 0.8),\n","                                nn.LeakyReLU(0.2, inplace=True),\n","                                nn.Linear(512, 1024),\n","                                nn.BatchNorm1d(1024, 0.8),\n","                                nn.LeakyReLU(0.2, inplace=True),\n","                                nn.Linear(1024,2048),\n","                                nn.BatchNorm1d(2048, 0.8),\n","                                nn.LeakyReLU(0.2, inplace=True),\n","                                nn.Linear(2048,784),\n","                                nn.Tanh()\n","                                )       \n","  def forward(self, latent, labels):\n","    inp = torch.cat((self.label(labels), latent), 1)\n","    out = self.layers(inp);\n","    out = out.view((out.size(0),1,28,28))\n","    return out\n","\n","  def __call__(self, latent, labels):\n","    return self.forward(latent, labels)\n","\n","class Discriminator(nn.Module):\n","  def __init__(self, n_class = NUM_CLASSES):\n","    super(Discriminator, self).__init__()\n","    self.label = nn.Embedding(n_class, 10)\n","    self.layers = nn.Sequential(nn.Linear(784 + 10, 1024),                    \n","                                nn.LeakyReLU(0.2, inplace=True),\n","                                nn.Linear(1024,512),\n","                                nn.LeakyReLU(0.2, inplace=True),\n","                                nn.Linear(512,256),\n","                                nn.LeakyReLU(0.2, inplace=True),\n","                                nn.Linear(256, 1),\n","                                nn.Sigmoid()\n","                                )\n","    \n","  def forward(self, image, labels):\n","      inp = torch.cat((image.view(image.size(0), -1), self.label(labels)), 1)\n","      decision = self.layers(inp)\n","      return decision\n","\n","  def __call__(self, image, labels):\n","      return self.forward(image, labels)"],"metadata":{"id":"ZMY4OXhHjjqF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.optim import Adam, SGD\n","#from torchvision.datasets import MNIST\n","from array2gif import write_gif\n","from torch.autograd import Variable\n","import os\n","import torchvision\n","\n","# try:\n","#   data_path = os.path.join(os.path.abspath(os.environ[\"CONDA_PREFIX\"]),\n","#                           'datasets')\n","# except KeyError:\n","#     data_path = os.path.join(os.path.abspath(os.environ[\"HOME\"]),\n","#                          'datasets')\n","# # We make sure that the dataset is actually available\n","# try:\n","#     torchvision.datasets.MNIST(root=data_path,\n","#                                download=False)\n","# except RuntimeError or KeyError:\n","#     if not os.path.isdir(data_path):\n","#             os.makedirs(data_path)\n","#     torchvision.datasets.MNIST(root=data_path,\n","#                                download=True)\n","\n","\n","dataset = torchvision.datasets.MNIST(root=data_path,download=True)\n","dataset.transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n","                                                    torchvision.transforms.Normalize(mean = (0.5,), \n","                                                                                     std = (0.5,))])\n","\n","def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find(\"Linear\") != -1:\n","        torch.nn.init.kaiming_uniform_(m.weight.data)\n","\n","# Device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","#device = torch.device('cpu')\n","print(\"Device is: \" + str(device))\n","\n","# Data Loader\n","batch_size = 128\n","data_loader = torch.utils.data.DataLoader(dataset=dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=True, drop_last=True)\n","generator     = Generator().to(device).apply(weights_init)\n","discriminator = Discriminator().to(device).apply(weights_init)\n","\n","criterion = nn.BCELoss()\n","\n","optim_d = Adam(discriminator.parameters(), lr=0.00001)\n","optim_g = Adam(generator.parameters(), lr=0.00002)\n","gif_array = []*EPOCH_SIZE\n","total_step = len(data_loader)\n","for epoch in range(EPOCH_SIZE):\n","  for step, (imgs, labels) in enumerate(data_loader):\n","\n","    # Ground truths\n","    if epoch < 100:\n","      real_truth = torch.normal(0.9 + (epoch/1000), 0.1001 - (epoch/1000), size = (batch_size, 1)).to(device)\n","      fake_truth = torch.normal(0.1 - + (epoch/1000), 0.10001 - (epoch/1000), size = (batch_size, 1)).to(device)\n","    else:\n","      real_truth = torch.ones(batch_size, 1).to(device)\n","      fake_truth = torch.zeros(batch_size, 1).to(device)\n","    # Labels\n","    real_labels = Variable(labels).to(device)\n","    real_imgs   = Variable(imgs).to(device)\n","\n","    # Create latent space and labels\n","    lat_space = torch.normal(0, 1, size=(batch_size, LATENT_SIZE)).to(device)\n","    lat_labels = torch.randint(low = 0, high = NUM_CLASSES, size = (batch_size,)).to(device)\n","    gnrt_imgs = generator(lat_space, lat_labels)\n","\n","    # ================================================================== #\n","    #                        Train the generator                         #\n","    # ================================================================== #\n","    \n","    # Compute loss with fake images\n","    f_outputs = discriminator(gnrt_imgs, lat_labels)\n","    g_loss = criterion(f_outputs, real_truth)\n","\n","    # Backprop and optimize\n","    optim_d.zero_grad()\n","    optim_g.zero_grad()\n","    g_loss.backward(retain_graph=True)\n","    optim_g.step()\n","\n","    # ================================================================== #\n","    #                      Train the discriminator                       #\n","    # ================================================================== #\n","    gnrt_imgs = generator(lat_space, lat_labels)\n","    # Real Images\n","    r_outputs     = discriminator(real_imgs, real_labels)\n","    d_loss_real = criterion(r_outputs, real_truth)\n","\n","    # BCE on fake images\n","    outputs = discriminator(gnrt_imgs, lat_labels)\n","    d_loss_fake = criterion(outputs, fake_truth)\n","\n","    # Backprop and optimize\n","    d_loss = d_loss_real + d_loss_fake\n","    optim_d.zero_grad()\n","    optim_g.zero_grad()\n","    d_loss.backward()\n","    optim_d.step()\n","\n","    if (step+1) % 200 == 0:\n","        print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n","                .format(epoch, EPOCH_SIZE, \n","                        step+1, total_step, \n","                        d_loss.item(), \n","                        g_loss.item(), \n","                        d_loss_real.mean().item(), \n","                        d_loss_fake.mean().item()))\n","  # Generate sample images\n","  lat_space = torch.randn(NUM_CLASSES**2, LATENT_SIZE).cuda()\n","  lat_labels = Variable(torch.IntTensor([lab for i in range(NUM_CLASSES) for lab in range(NUM_CLASSES)])).cuda()\n","  sample_images = generator(lat_space, lat_labels)\n","  # Plot\n","  if epoch%5 == 0:\n","    plot_epoch(sample_images.cpu())\n","  array_2_make_grid = ((sample_images.cpu()[0:ROW_NUM**2, :, :, :] + 1) * (1/2) * 255).type(torch.uint8)\n","  gif_array.append(torchvision.utils.make_grid(array_2_make_grid, nrow = ROW_NUM).numpy())\n","write_gif(gif_array, filename = 'cgan_25_fps.gif', fps = 25)"],"metadata":{"id":"354CJ5u3jncg"},"execution_count":null,"outputs":[]}]}